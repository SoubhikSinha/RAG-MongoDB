# `RAG` @ MongoDB

This repository demonstrates an end-to-end **Retrieval-Augmented Generation (RAG)** pipeline using **MongoDB as a vector database** and the **OpenAI embedding model `text-embedding-3-large`**, integrating document ingestion, intelligent chunking, vector embedding, and semantic retrieval to deliver highly relevant, context-aware responses from Large Language Models. It covers the full lifecycle of a RAG system—from preprocessing raw data and generating embeddings to storing vectors, performing similarity search, and augmenting prompts with retrieved context—making the workflow easy to understand and extend. The project highlights practical strategies for improving RAG performance and answer quality through effective chunking, embedding consistency, and prompt construction. Designed as a hands-on learning reference, this implementation supports scalable, production-ready GenAI and question-answering applications while keeping the architecture modular and adaptable for enterprise or research use cases. _Deep gratitude to [Krish Naik](https://github.com/krishnaik06) for his educational guidance and open-source contributions that inspired this project._
